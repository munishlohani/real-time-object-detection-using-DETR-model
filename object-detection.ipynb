{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10aa36b1-ac19-40e2-9e6d-5c80c978daca",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39df8c69-e336-4552-9a77-9e5e0f8b67d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675206cb-c9b7-4235-a845-636495eb8ae9",
   "metadata": {},
   "source": [
    "# Setting up the Hugging Face Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078b8970-db37-4f6c-a16e-3ee6d75188c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"object-detection\", model=\"facebook/detr-resnet-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b340013-4adc-4a7e-af87-672ef2930307",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "model = AutoModelForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08bfc1f-465c-41fd-b80b-baf1601820c1",
   "metadata": {},
   "source": [
    "# Setting up Video Capture device\n",
    "\n",
    "### For errors in this step:\n",
    "- Change the device index i.e 0 -> 1/2/3... until the camera is accessible.\n",
    "\n",
    "\n",
    "## Keys:\n",
    "- press **'q'** to abort the operation.\n",
    "- press **'v'** to detect the object present in the screen.\n",
    "\n",
    "\n",
    "#### **Note**: The output may not always give the accurate result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca206290-1cdc-4977-b68b-6e5f71c26c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret,frame=cap.read()\n",
    "    \n",
    "    frame=(frame[200:200+600,100:100+800])\n",
    " \n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF==ord('v'):\n",
    "\n",
    "        cv2.imwrite(os.path.join('detection','input_image.jpg'),frame)\n",
    "        \n",
    "        image=Image.open(r'detection/input_image.jpg')\n",
    "        \n",
    "        inputs = processor(images=image, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs)\n",
    "                    \n",
    "            \n",
    "        target_sizes = torch.tensor([image.size[::-1]])\n",
    "        results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n",
    "                    \n",
    "        for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "             box = [round(i, 2) for i in box.tolist()]\n",
    "             print(\n",
    "             f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
    "             f\"{round(score.item(), 3)} at location {box} \"\n",
    "            f\"\\n\"\n",
    "             )\n",
    "        \n",
    "    cv2.imshow('Webcam',frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25abb50-72f7-4472-81ac-37e9f217fcff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
