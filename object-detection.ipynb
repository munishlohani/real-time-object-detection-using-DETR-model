{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39df8c69-e336-4552-9a77-9e5e0f8b67d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "078b8970-db37-4f6c-a16e-3ee6d75188c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"object-detection\", model=\"facebook/detr-resnet-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b340013-4adc-4a7e-af87-672ef2930307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "model = AutoModelForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca206290-1cdc-4977-b68b-6e5f71c26c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 0.981 at location [21.7, 21.52, 437.84, 278.1] \n",
      "\n",
      "Detected cell phone with confidence 0.988 at location [62.14, 73.57, 529.74, 156.0] \n",
      "\n",
      "Detected person with confidence 0.938 at location [12.58, 21.88, 531.06, 278.18] \n",
      "\n",
      "Detected cell phone with confidence 0.984 at location [51.96, 77.09, 522.88, 157.33] \n",
      "\n",
      "Detected person with confidence 0.957 at location [14.64, 19.75, 528.16, 277.96] \n",
      "\n",
      "Detected person with confidence 0.997 at location [11.65, 18.99, 525.89, 277.94] \n",
      "\n",
      "Detected person with confidence 0.93 at location [321.7, 78.51, 539.1, 276.62] \n",
      "\n",
      "Detected person with confidence 0.988 at location [18.56, 26.92, 390.84, 277.46] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret,frame=cap.read()\n",
    "    \n",
    "    frame=(frame[200:200+600,100:100+800])\n",
    " \n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF==ord('v'):\n",
    "\n",
    "        cv2.imwrite(os.path.join('detection','input_image.jpg'),frame)\n",
    "        \n",
    "        image=Image.open(r'detection/input_image.jpg')\n",
    "        \n",
    "        inputs = processor(images=image, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs)\n",
    "                    \n",
    "            \n",
    "        target_sizes = torch.tensor([image.size[::-1]])\n",
    "        results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n",
    "                    \n",
    "        for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "             box = [round(i, 2) for i in box.tolist()]\n",
    "             print(\n",
    "             f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
    "             f\"{round(score.item(), 3)} at location {box} \"\n",
    "            f\"\\n\"\n",
    "             )\n",
    "        \n",
    "    cv2.imshow('Webcam',frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25abb50-72f7-4472-81ac-37e9f217fcff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
